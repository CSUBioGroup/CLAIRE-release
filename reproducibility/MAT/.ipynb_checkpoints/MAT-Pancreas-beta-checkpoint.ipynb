{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sps\n",
    "\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from MAT2 import *\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from os.path import join\n",
    "cur_dir = Path(os.getcwd())\n",
    "sys.path.append(str(cur_dir.parent.parent.absolute()))\n",
    "\n",
    "from moco.kbet import calculate_kbet\n",
    "from moco.utils import py_read_data, load_meta_txt\n",
    "from moco.preprocessing import hvgPipe\n",
    "from scib_eval import scib_eval\n",
    "\n",
    "data_dir = '/home/yxh/gitrepo/Batch-effect-removal-benchmarking-master/Script/sapling/GLOBE/data'\n",
    "out_dir = '/home/yxh/gitrepo/Batch-effect-removal-benchmarking-master/Output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reading cost time 0.1102 secs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# prepare datasets\n",
    "# ================================\n",
    "dno = 'Pancreas'\n",
    "sc.settings.set_figure_params(dpi=80)\n",
    "sc.settings.figdir = Path(f'/home/yxh/gitrepo/Batch-effect-removal-benchmarking-master/Output/dataset4/MAT')\n",
    "sc.settings.figdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_dir = join(data_dir, dno)\n",
    "# data_name = 'b1_exprs'\n",
    "batch_key = 'batch'\n",
    "label_key = 'type'\n",
    "\n",
    "sps_x, gene_name, cell_name = py_read_data(dataset_dir, 'myData_pancreatic_5batches')\n",
    "df_meta = load_meta_txt(join(dataset_dir, 'mySample_pancreatic_5batches.txt'))\n",
    "df_meta[label_key] = df_meta['celltype']\n",
    "df_meta[batch_key] = df_meta['batchlb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'batch' as categorical\n",
      "... storing 'type' as categorical\n",
      "/home/yxh/.local/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# preprocessing\n",
    "# ================================\n",
    "\n",
    "min_cells = 3\n",
    "scale_factor = 1e4\n",
    "n_hvgs = 2000\n",
    "\n",
    "adata = sc.AnnData(sps.csr_matrix(sps_x.T))  # transposed before\n",
    "adata.obs_names = cell_name\n",
    "adata.var_names = gene_name\n",
    "adata.obs[batch_key] = df_meta.loc[cell_name, batch_key]\n",
    "# change the batch from number to string \n",
    "# adata.obs[batch_key] = adata.obs[batch_key].apply(lambda x: f'Batch{int(x)+1}')\n",
    "adata.obs[label_key] = df_meta.loc[cell_name, label_key]\n",
    "\n",
    "\n",
    "sc.pp.filter_genes(adata, min_cells=min_cells) \n",
    "sc.pp.normalize_total(adata, target_sum=scale_factor)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=min(adata.shape[1]-1, n_hvgs), \n",
    "                            min_mean=0.0125, max_mean=3, min_disp=0.5,\n",
    "                            batch_key=batch_key)\n",
    "\n",
    "adata = adata[:, adata.var.highly_variable].copy()\n",
    "\n",
    "data = pd.DataFrame(adata.X.A.T, index=adata.var_names, columns=cell_name)\n",
    "# prepare anchors\n",
    "anchor = pd.read_csv(join(dataset_dir, f'seuratAnchors.csv'), header=0, index_col=0)\n",
    "\n",
    "# compute the absolute cell.idx in the X\n",
    "name2idx = dict(zip(adata.obs_names, np.arange(adata.shape[0])))\n",
    "anchor['cell1'] = anchor.name1.apply(lambda x:name2idx[x])\n",
    "anchor['cell2'] = anchor.name2.apply(lambda x:name2idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Unsupervised training========\n",
      "training params  0.0001 10\n",
      "\n",
      "\n",
      "\n",
      "Training finish!\n",
      "\n",
      "training params  0.0001 20\n",
      "\n",
      "\n",
      "\n",
      "Training finish!\n",
      "\n",
      "training params  0.0001 40\n",
      "\n",
      "\n",
      "\n",
      "Training finish!\n",
      "\n",
      "training params  0.0001 60\n",
      "\n",
      "\n",
      "\n",
      "Training finish!\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hvgPipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2a13ea6a04ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mRES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mad_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhvgPipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mad_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobsm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_emb'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mad_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobsm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_pca'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hvgPipe' is not defined"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# training Unsupervised model\n",
    "# ================================\n",
    "print('========Unsupervised training========')\n",
    "lr = 1e-3\n",
    "eps = [10, 40, 60, 80]\n",
    "EMBS = []\n",
    "for ep in eps:\n",
    "    print('training params ', lr, ep)\n",
    "    model_unv = BuildMAT2(\n",
    "                        data=data,\n",
    "                        metadata=df_meta,\n",
    "                        anchor=anchor,\n",
    "                        num_workers=6,\n",
    "                        use_gpu=True,\n",
    "                        mode='manual',\n",
    "                        latent_num = 20,\n",
    "                        learning_rate = lr,\n",
    "                        batch_size = 256,\n",
    "                        norm = 'l1',\n",
    "                        weight_decay = 0.01)\n",
    "    model_unv.train(epochs=ep, curve=False, dec_train=True)\n",
    "\n",
    "    rec_unv = model_unv.evaluate(data)\n",
    "    EMBS.append(rec_unv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI...\n",
      "ARI...\n",
      "Silhouette score...\n",
      "Calculating kbet...\n",
      "Making the column batch of adata.obs categorical.\n",
      "NMI...\n",
      "ARI...\n",
      "Silhouette score...\n",
      "Calculating kbet...\n",
      "Making the column batch of adata.obs categorical.\n",
      "NMI...\n",
      "ARI...\n",
      "Silhouette score...\n",
      "Calculating kbet...\n",
      "Making the column batch of adata.obs categorical.\n",
      "NMI...\n",
      "ARI...\n",
      "Silhouette score...\n",
      "Calculating kbet...\n",
      "Making the column batch of adata.obs categorical.\n"
     ]
    }
   ],
   "source": [
    "RES = None\n",
    "for i,ep in enumerate(eps):\n",
    "    ad_tmp = hvgPipe(EMBS[i], meta=df_meta, scale=True, n_neighbors=15, npcs=50, umap=True)\n",
    "    ad_tmp.obsm['X_emb'] = ad_tmp.obsm['X_pca']\n",
    "\n",
    "    tmp_res = scib_eval(ad_tmp, batch_key, label_key)\n",
    "\n",
    "    RES = tmp_res if RES is None else RES.merge(tmp_res, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "RES.columns = eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>40</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NMI_cluster/label</th>\n",
       "      <td>0.893826</td>\n",
       "      <td>0.895380</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.890757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARI_cluster/label</th>\n",
       "      <td>0.937854</td>\n",
       "      <td>0.940682</td>\n",
       "      <td>0.943553</td>\n",
       "      <td>0.940851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASW_label</th>\n",
       "      <td>0.569635</td>\n",
       "      <td>0.568234</td>\n",
       "      <td>0.570562</td>\n",
       "      <td>0.596670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASW_label/batch</th>\n",
       "      <td>0.832243</td>\n",
       "      <td>0.848692</td>\n",
       "      <td>0.841847</td>\n",
       "      <td>0.841750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isolated_label_F1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isolated_label_silhouette</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graph_conn</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trajectory</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kBET</th>\n",
       "      <td>0.354845</td>\n",
       "      <td>0.371165</td>\n",
       "      <td>0.401571</td>\n",
       "      <td>0.400826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 10        20        40        60\n",
       "NMI_cluster/label          0.893826  0.895380  0.899471  0.890757\n",
       "ARI_cluster/label          0.937854  0.940682  0.943553  0.940851\n",
       "ASW_label                  0.569635  0.568234  0.570562  0.596670\n",
       "ASW_label/batch            0.832243  0.848692  0.841847  0.841750\n",
       "isolated_label_F1               NaN       NaN       NaN       NaN\n",
       "isolated_label_silhouette       NaN       NaN       NaN       NaN\n",
       "graph_conn                      NaN       NaN       NaN       NaN\n",
       "trajectory                      NaN       NaN       NaN       NaN\n",
       "kBET                       0.354845  0.371165  0.401571  0.400826"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch171",
   "language": "python",
   "name": "torch171"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
