{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "import scanorama\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from os.path import join\n",
    "cur_dir = Path(os.getcwd())\n",
    "sys.path.append(str(cur_dir.parent.absolute()))\n",
    "sys.path.append(str(cur_dir.parent.parent.parent.absolute()))\n",
    "\n",
    "from moco.kbet import calculate_kbet\n",
    "from moco.utils import py_read_data, load_meta_txt\n",
    "from moco.evaluation import scib_process \n",
    "from moco.prepare_dataset import prepare_dataset\n",
    "from moco.preprocessing import embPipe, preprocess_dataset\n",
    "\n",
    "from SMILE import SMILE\n",
    "from SMILE.SMILE import SMILE_trainer\n",
    "from SMILE.utils import py_read_data, load_meta_txt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "from scib_eval import scib_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing dataset, shape=(5000, 67354)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yxh/anaconda3/envs/torch171/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# prepare datasets\n",
    "# ================================\n",
    "data_root = '/home/yxh/gitrepo/Batch-effect-removal-benchmarking-master/Script/sapling/GLOBE/data'\n",
    "\n",
    "dno = 'Muris'\n",
    "dataset_dir = join(data_root, dno)\n",
    "\n",
    "n_hvgs = 5000\n",
    "scale = False\n",
    "batch_key = 'batchlb'\n",
    "label_key = 'CellType'\n",
    "\n",
    "sps_x, genes, cells, df_meta = prepare_dataset(dataset_dir)\n",
    "X, cell_name, gene_name, df_meta = preprocess_dataset(\n",
    "    sps_x, \n",
    "    cells, \n",
    "    genes, \n",
    "    df_meta, \n",
    "    n_hvgs, \n",
    "    scale, \n",
    ")\n",
    "\n",
    "\n",
    "adata_hvg = sc.AnnData(X)\n",
    "adata_hvg.var_names = gene_name\n",
    "adata_hvg.obs = df_meta.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_hvg_scale = adata_hvg.copy()\n",
    "\n",
    "X = adata_hvg.X\n",
    "X = X.A if sps.issparse(X) else X.copy()\n",
    "\n",
    "scaler = StandardScaler()##scaling\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "adata_hvg_scale.X = sps.csr_matrix(X)\n",
    "adata_hvg_scale.write(join(dataset_dir, f'NormLogScale-{dno}.h5ad'))  # for clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================\n",
    "# Training\n",
    "# ================================\n",
    "def weights_init(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "X = adata_hvg.X \n",
    "X = X.A if sps.issparse(X) else X.copy()\n",
    "\n",
    "scaler = StandardScaler()##scaling\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "##3. Use SMILE for single-cell RNA-seq data\n",
    "X_all_tensor = torch.tensor(X).float()\n",
    "\n",
    "# training params\n",
    "clf_out = 25\n",
    "batch_size = 512\n",
    "lr = 1e-2\n",
    "num_epoch = 80\n",
    "EPS = [80]  # 10, 20, 40, 80\n",
    "\n",
    "net = SMILE.SMILE(input_dim=X.shape[1],clf_out=clf_out)   # input_dim, \n",
    "net.apply(weights_init) ##initialize weights, only once\n",
    "\n",
    "# log\n",
    "log_dir = f'../outputs/{dno}-0.01'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "SMILE_trainer(X,\n",
    "              net,\n",
    "              lr=lr,   # 1e-2, 1e-4 tried\n",
    "              batch_size = batch_size, \n",
    "              num_epoch=num_epoch,\n",
    "              f_temp = 0.05, \n",
    "              p_temp = 0.15,\n",
    "              log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================\n",
    "# inference\n",
    "# ================================\n",
    "ADAS = []\n",
    "for ep in [80]:\n",
    "    # loading checkpoint\n",
    "    ckpt_name = 'checkpoint_{:04d}.pth.tar'.format(ep)\n",
    "    checkpoint = torch.load(join(log_dir, 'weights1', ckpt_name))\n",
    "\n",
    "    net.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    print(\"=> loaded checkpoint: {}\"\n",
    "          .format(ckpt_name))\n",
    "\n",
    "    net.to(torch.device(\"cpu\"))\n",
    "    y_pred = np.zeros((X.shape[0],128))\n",
    "\n",
    "    for j in range(X.shape[0]//batch_size+1):\n",
    "        pred = net.encoder(X_all_tensor[j*batch_size:(j+1)*batch_size, :])  # 再看到这里，才发现SMILE是个完整的MocoV2模型\n",
    "        pred = torch.Tensor.cpu(pred).detach().numpy()\n",
    "        y_pred[j*batch_size:(j+1)*batch_size, :]=pred\n",
    "\n",
    "    # convert to scanpy obj\n",
    "    ada_tmp = embPipe(y_pred, df_meta)\n",
    "    ada_tmp.obsm[\"X_emb\"] = ada_tmp.X\n",
    "    ADAS.append(ada_tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch171",
   "language": "python",
   "name": "torch171"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
